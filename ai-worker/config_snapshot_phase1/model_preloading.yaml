config_version: "1.0"

# Model Preloading Configuration
# Controls how models are loaded at startup and on-demand

# Preloading policy
preload_on_startup: false  # Don't preload models on startup (safe mode)
warmup_enabled: true  # Run warmup after loading
load_on_demand: true  # Load models when first requested

# Background loading
background_loading_enabled: false  # Load models in background
background_loading_priority:  # Models to load in background (if enabled)
  - phi-3-mini  # LLM
  - whisper-tiny  # STT

# Warmup configuration
warmup_tokens: 10  # Number of tokens for warmup inference
warmup_timeout: 30  # Warmup timeout in seconds

# Preload triggers
preload_on_user_login: false  # Preload when user logs in
preload_on_idle: true  # Preload when system is idle
idle_threshold_minutes: 5  # Minutes of inactivity before considering idle

# Model priority (higher = load first)
model_priority:
  phi-3-mini: 10
  whisper-tiny: 9
  whisper-base: 5
  pyttsx3: 8

# Memory management
max_preloaded_models: 2  # Maximum models to keep preloaded
unload_after_minutes: 10  # Unload unused models after N minutes
